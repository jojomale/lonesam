{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea00019b-4f65-4aea-bcf3-9b9d5431c7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    " filehead = os.path.join(self.datadir, self.stationcode)\n",
    "        fmtstr = filehead + \"_{:04d}*.hdf5\"\n",
    "        logger.info(\"Looking for data file %s\" % fmtstr)\n",
    "        _year = self.sdate.year\n",
    "        files = []\n",
    "        while _year <= self.edate.year:\n",
    "            searchstr = fmtstr.format(_year)\n",
    "            fnames = glob(searchstr)\n",
    "\n",
    "            if len(fnames) > 1:\n",
    "                files.append(self.select_longest(fnames))\n",
    "            elif len(fnames) == 0:\n",
    "                _year = _year +1\n",
    "                continue\n",
    "            else:\n",
    "                files.append(fnames[0])\n",
    "\n",
    "            # Get end year of latest file\n",
    "            ## Remove file-ext and path\n",
    "            f, ext = os.path.splitext(files[-1])\n",
    "            _endtime = UTC(f.split('_')[-1])\n",
    "            if _endtime.year >= self.endtime.year:\n",
    "                break\n",
    "            _year = _year + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7e538f-c810-435f-913b-119691acf4b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import os\n",
    "from datetime import timedelta\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import h5py\n",
    "\n",
    "from obspy.clients.filesystem.sds import Client\n",
    "from obspy.clients.fdsn import RoutingClient\n",
    "from obspy.core import UTCDateTime as UTC\n",
    "from obspy.signal import util\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('tableau-colorblind10')\n",
    "\n",
    "from data_quality_control import base, sds_db\n",
    "#from data_quality_control import processing\n",
    "#from data_quality_control.processing import ProcessingParameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "134d261f-9f3c-460a-acd4-07af91e57dab",
   "metadata": {},
   "outputs": [],
   "source": [
    "overlap = 60 #3600\n",
    "fmin, fmax = (4, 14)\n",
    "nperseg = 2048\n",
    "winlen_in_s = 3600\n",
    "proclen = 24*3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3039fb80-ae40-4de9-8751-15243f021bef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('tableau-colorblind10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab9c11f-0ca9-421e-9df3-508d14e9a67a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import configparser\n",
    "from datetime import timedelta, time\n",
    "from glob import glob\n",
    "import os.path\n",
    "import numpy as np\n",
    "\n",
    "#from scipy.signal import welch, get_window\n",
    "\n",
    "#from obspy.signal.filter import bandpass\n",
    "#from obspy.clients.filesystem.sds import Client\n",
    "#from obspy.clients.fdsn import RoutingClient\n",
    "from obspy.core import UTCDateTime as UTC\n",
    "# from obspy.signal import util\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "import h5py\n",
    "\n",
    "from data_quality_control import base, sds_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc4ee9c-2f30-420f-91b4-2080e0c001c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logger = logging.getLogger('processing')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "ch = logging.StreamHandler()\n",
    "ch.setLevel(logging.DEBUG)  # set level\n",
    "cformatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s',\n",
    "                            datefmt='%y-%m-%d %H:%M:%S')\n",
    "ch.setFormatter(cformatter)\n",
    "if not logger.hasHandlers():\n",
    "    logger.addHandler(ch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ac387e7-5a33-49b9-a0f8-8d78c87bb56b",
   "metadata": {},
   "source": [
    "# Develop base analysizer for new data layout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6578ca48-4ba6-4555-9122-75254f6157c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Analyzer():\n",
    "    def __init__(self, sdate, edate, \n",
    "                 datadir, stationcode, fileunit=\"year\",\n",
    "                stime=\"00:00\", etime=\"23:59:59:999999\"):\n",
    "        self.sdate = UTC(sdate).date\n",
    "        self.edate = UTC(edate).date\n",
    "        self._update_time(stime, etime)\n",
    "        self._update_datetime()\n",
    "        self.datadir = datadir\n",
    "        self.stationcode = stationcode\n",
    "        self.fileunit  = fileunit\n",
    "        self.iter_time = base.TIME_ITERATORS[self.fileunit]\n",
    "        \n",
    "        # Get fmtstr of data files\n",
    "        fmtstr_base, sep, fmtstr_time = base.FNAME_FMTS[self.fileunit].rpartition(\"_\")\n",
    "        self.fmtstr = (fmtstr_base.format(\n",
    "                        outdir=self.datadir, **self.nslc_as_dict()) + \n",
    "                        sep + fmtstr_time)\n",
    "        \n",
    "        \n",
    "        self.files = self.get_filenames()\n",
    "        \n",
    "        \n",
    "        #self.get_data()\n",
    "    def nslc_as_dict(self):\n",
    "        d = {k: v for k, v in zip([\"network\", \"station\", \"location\", \"channel\"], \n",
    "                                  self.stationcode.split(\".\"))}\n",
    "        return d\n",
    "    \n",
    "    \n",
    "    def _tstr2time(self, t):\n",
    "        return time(*[int(s) for s in t.split(':')])\n",
    "        \n",
    "            \n",
    "    def _update_datetime(self):\n",
    "        self.starttime = UTC(\"{}T{}\".format(self.sdate, self.stime))\n",
    "        self.endtime = UTC(\"{}T{}\".format(self.edate, self.etime))\n",
    "\n",
    "\n",
    "    def _update_time(self, stime, etime):\n",
    "        if stime:\n",
    "            self.stime = self._tstr2time(stime)\n",
    "        if etime:\n",
    "            self.etime = self._tstr2time(etime)\n",
    "        self._update_datetime()\n",
    "    \n",
    "\n",
    "    def get_all_data(self, sdate=None, edate=None, \n",
    "                 datadir=None, stationcode=None):\n",
    "        if sdate is not None:\n",
    "            self.sdate = UTC(sdate)\n",
    "        if edate is not None:\n",
    "            self.edate = UTC(sdate)\n",
    "        if datadir is not None:\n",
    "            self.datadir = datadir\n",
    "        if stationcode is not None:\n",
    "            self.stationcode = stationcode\n",
    "        self._update_datetime()\n",
    "            \n",
    "        files = sorted(self.get_filenames())\n",
    "        if len(files) == 0:\n",
    "            logger.warn(\"No files for %s in %s between %s and %s\" %\n",
    "                        (self.stationcode, self.datadir, \n",
    "                        self.sdate, self.edate))\n",
    "            return\n",
    "        \n",
    "        # If we found files, a\n",
    "        data = processing.BaseProcessedData()\n",
    "        for file in files:\n",
    "            data.extend_from_file(file)\n",
    "        self.data = data\n",
    "            \n",
    "        \n",
    "            \n",
    "    def get_filenames(self):\n",
    "        \n",
    "        \n",
    "        logger.info(\"Looking for data file %s\" % self.fmtstr)\n",
    "        files = []\n",
    "        \n",
    "        \n",
    "        for starttime, endtime in self.iter_time(self.starttime, self.endtime):\n",
    "            files.append(self.fmtstr.format(year=starttime.year, \n",
    "                                        month=starttime.month, \n",
    "                                        day=starttime.day,\n",
    "                                        hour=starttime.hour))\n",
    "   \n",
    "        return files\n",
    "\n",
    "\n",
    "\n",
    "    def select_longest(self, fnames):\n",
    "        logger.debug(\"Found %s files for year.\" % \n",
    "                     str(len(fnames)))\n",
    "        f, ext = os.path.splitext(fnames[0])\n",
    "        print(f.split('_')[-1])\n",
    "        edate = UTC(f.split('_')[-1])\n",
    "        for _f in fnames[1:]:\n",
    "            _f = os.path.split(\n",
    "                    os.path.splitext(\n",
    "                        _f)[0])[-1]\n",
    "            _edate = UTC(_f.split('_')[-1])\n",
    "            if _edate >= edate:\n",
    "                edate = _edate\n",
    "            if edate >= self.endtime:\n",
    "                break\n",
    "        print(f+ext)\n",
    "        return f+ext\n",
    "    \n",
    "    \n",
    "    def iter_files(self):\n",
    "        \"\"\"\n",
    "        Generator that returns open h5py.File object for\n",
    "        each filename in self.files.\n",
    "        \"\"\"\n",
    "        for fname in self.files:\n",
    "            logger.debug(\"Opening file %s\" % fname)\n",
    "            try:\n",
    "                val = h5py.File(fname, 'r')\n",
    "                # Return file object\n",
    "                yield val\n",
    "                # Close before proceding\n",
    "                val.close()\n",
    "            # Always close file before we \n",
    "            # present the error\n",
    "            except:\n",
    "                val.close()\n",
    "                logger.error(\"Error while opening file %s\" % fname)\n",
    "                raise\n",
    "                \n",
    "            \n",
    "    def get_data(self, \n",
    "                 stime=None, etime=None):\n",
    "        \n",
    "        DATA = base.BaseProcessedData()\n",
    "        for fname in self.files:\n",
    "            print(fname)\n",
    "            DATA.extend_from_file(fname)\n",
    "        \n",
    "        # Cut out desired time range\n",
    "        self._update_time(stime, etime)\n",
    "        \n",
    "        \n",
    "        i = int((self.starttime - DATA.startdate) / \n",
    "                    DATA.proclen_seconds)\n",
    "        j = int((self.endtime + DATA.proclen_seconds - DATA.startdate) / \n",
    "                        DATA.proclen_seconds)\n",
    "        \n",
    "        print(i, j)\n",
    "        self.amps = DATA.amplitudes[i:j,:]\n",
    "\n",
    "        self.psds = DATA.psds[i:j,:]\n",
    "        self.freqax = DATA.frequency_axis\n",
    "        self.proclen_seconds = DATA.proclen_seconds\n",
    "        self.winlen_seconds = DATA.seconds_per_window\n",
    "        self.nwin = self.amps.shape[1]\n",
    "        return DATA\n",
    "                \n",
    "    def infostr(self):\n",
    "        t = (self.stationcode + \"<br>\" +\n",
    "            \"{} - {}<br>\".format(self.sdate, self.edate) +\n",
    "            \"{} - {}\".format(self.stime, self.etime))\n",
    "        return t\n",
    "\n",
    "\n",
    "    def plot(self):\n",
    "        return self.plot_amplitudes(), self.plot_psds()\n",
    "\n",
    "\n",
    "    def plot_amplitudes(self, func=None):\n",
    "\n",
    "        title = (\"Hourly 75%-amplitude<br>\" + \n",
    "                    self.infostr()\n",
    "            )\n",
    "\n",
    "        if func:\n",
    "            z = func(self.amps)\n",
    "        else:\n",
    "            z = self.amps\n",
    "        dateax, timeax = self._get_time_axis()\n",
    "        \n",
    "        # Numpy-datetime can give you a **really** hard time to convert\n",
    "        # between the different increments....\n",
    "        xticks = [str(timedelta(\n",
    "            **{np_td2datetime_td_keywords[str(timeax.dtype)] : int(np.int64(s))})) \n",
    "               for s in timeax]\n",
    "        \n",
    "        char = str(timeax.dtype)[-2]\n",
    "        #timeax = np.array(timeax, dtype=np.datetime64(None, char))\n",
    "        print(xticks, timeax)\n",
    "        fig = self._plotly_3dsurface(timeax, dateax, z,\n",
    "                        name=\"amplitudes\")\n",
    "\n",
    "        #xticks = [str(s).split(\"T\")[-1] for s in timeax]\n",
    "        \n",
    "        fig.update_layout(title=title,\n",
    "            scene=dict(\n",
    "                xaxis=dict(title='Time', ticktext=xticks, tickvals=timeax),\n",
    "                yaxis=dict(title='Date'),\n",
    "                zaxis=dict(title=\"m/s\")\n",
    "            )\n",
    "        )\n",
    "        return fig\n",
    "\n",
    "        \n",
    "\n",
    "    def plot_psds(self, func=None):\n",
    "\n",
    "        title = (\"Hourly power spectral density\\n\" + \n",
    "                    self.infostr()\n",
    "            )\n",
    "        if func:\n",
    "            z = func(self.psds)\n",
    "        else:\n",
    "            z = self.psds\n",
    "        try:\n",
    "            funcname = func.__name__+\"(\", \")\"\n",
    "        except AttributeError:\n",
    "            funcname = \"\", \"\"\n",
    "        nwin = z.shape[1]\n",
    "        z = z.reshape((z.shape[0]*z.shape[1], z.shape[2]))\n",
    "        dateax, timeax = self._get_time_axis()\n",
    "        datetimeax = dateax[:,None] + timeax[None,:]\n",
    "        y = datetimeax.ravel()\n",
    "        x = self.freqax\n",
    "        fig = self._plotly_3dsurface(x, y, z, name=\"psds\")\n",
    "        fig.update_layout(title=title, \n",
    "                        scene=dict(\n",
    "                            xaxis=dict(title='Frequency, Hz'),\n",
    "                            yaxis=dict(title='Datetime'),\n",
    "                            zaxis=dict(title=\"psd, {}m^2/s^2/Hz{}\".format(*funcname)\n",
    "                                        )\n",
    "                                )\n",
    "                            ),\n",
    "                        \n",
    "        return fig\n",
    "\n",
    "    def _plotly_3dsurface(self,x,y, z, name=None, cmin=None, cmax=None):\n",
    "        #sh_0, sh_1 = z.shape\n",
    "        #y, x = np.linspace(0, sh_0-1, sh_0), np.linspace(0, sh_1-1, sh_1)\n",
    "        fig = go.Figure(data=[go.Surface(z=z, x=x, y=y, name=name, \n",
    "                                            cmin=cmin, cmax=cmax)])\n",
    "        fig.update_layout(autosize=True,\n",
    "                          width=800, height=500,\n",
    "                          scene=dict(aspectmode='manual',\n",
    "                                     aspectratio=dict(x=1, y=2, z=0.5))\n",
    "                          #margin=dict(l=65, r=50, b=65, t=90)\n",
    "                         )\n",
    "        #fig.show()\n",
    "        return fig\n",
    "\n",
    "\n",
    "    def _get_time_axis(self):\n",
    "        sdate = np.datetime64(self.sdate, 'h')\n",
    "        edate = np.datetime64(self.edate, 'h') + np.timedelta64(1, \"D\")\n",
    "        dateax = np.arange(sdate, edate, np.timedelta64(1, \"D\"), \n",
    "                    dtype='datetime64')\n",
    "\n",
    "        dur = self.etime.hour - self.stime.hour\n",
    "        if dur <= 0:\n",
    "            dur = dur + 24\n",
    "\n",
    "        timeax = np.arange(dur+1, dtype=np.timedelta64) + self.stime.hour\n",
    "        \n",
    "        dtflag, dtinc = base.choose_datetime_inc(self.proclen_seconds)\n",
    "\n",
    "        dateax = np.arange(self.starttime, \n",
    "                            self.endtime+self.proclen_seconds,\n",
    "                            dtinc,\n",
    "                        dtype='datetime64[{}]'.format(dtflag))\n",
    "        \n",
    "        dtflag, dtinc = base.choose_datetime_inc(self.winlen_seconds)\n",
    "        dur = self.nwin*self.winlen_seconds\n",
    "        timeax = np.arange(0, int(dur/base.datetime_flags[dtflag])+dtinc, \n",
    "                           dtinc, \n",
    "                           dtype='datetime64[{}]'.format(dtflag))\n",
    "                                                \n",
    "        timeax = np.arange(0, self.nwin*dtinc, np.timedelta64(dtinc, dtflag))\n",
    "        #print(timeax)\n",
    "        return dateax, timeax\n",
    "        \n",
    "\n",
    "np_td2datetime_td_keywords = {'timedelta64[{}]'.format(v[0]) : v.lower() for \n",
    "                              v in [\"minutes\", \"hours\", \"Days\", \"Months\", \"Years\"]}\n",
    "\n",
    "\n",
    "\n",
    "dict(\n",
    "        m = \"minutes\",\n",
    "        h = \"hours\", \n",
    "        s = \"seconds\",\n",
    "        M = \"months\",\n",
    "    D = \"days\"\n",
    ")                                                \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078a421c-a023-485e-8be6-b482ad4809f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(base)\n",
    "# Station id\n",
    "network = 'GR'\n",
    "station = 'BFO'\n",
    "location = ''\n",
    "channel = 'HHZ'\n",
    "\n",
    "# Data source\n",
    "#datadir = '/home/lehr/sds/processed/'\n",
    "datadir = \".\"\n",
    "\n",
    "\n",
    "# Date range that you want to inspect\n",
    "startdate = UTC(\"2020-12-28\")\n",
    "enddate = UTC(\"2021-01-05\")\n",
    "\n",
    "\n",
    "# Choose time range \n",
    "## Full time range (= all 24h)\n",
    "stime, etime = \"00:00\", \"23:00\"\n",
    "\n",
    "## Time range crossing midnight\n",
    "#stime, etime = \"19:00\", \"05:00\"\n",
    "\n",
    "stationcode = \"{}.{}.{}.{}\".format(network, station, \n",
    "                               location, channel)\n",
    "analyzer = Analyzer(\n",
    "    startdate, enddate, datadir, stationcode, fileunit=\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02e36d4c-d946-4e3d-bef1-d2e9a24a982b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = analyzer.get_data(#[\"amplitudes\", \"psds\"], \n",
    "                    # stime=\"00:00\", etime=\"23:00\"\n",
    "                    stime=stime, etime=etime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d641a3f-4afd-47b8-b9cd-e5e61bc4c4a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.plot_amplitudes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fbc66ab-0fca-4630-8744-a37effe86426",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.plot_psds(np.log)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f95b0d4b-8738-4654-93cd-809461bc18ec",
   "metadata": {},
   "source": [
    "# Develop SDSBASEAnalyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a5215e3-e034-44a0-a65f-289283cbbf77",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_quality_control import analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779f7079-5527-4ecd-8f04-f61eaeb1d5a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SDSDataBaseAnalyzer(analysis.Analyzer):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "\n",
    "\n",
    "    def get_filenames(self):\n",
    "        \n",
    "        filehead = os.path.join(self.datadir, self.stationcode)\n",
    "        fmtstr = filehead + \"_{:04d}.hdf5\"\n",
    "        logger.info(\"Looking for data file %s\" % fmtstr)\n",
    "        _year = self.sdate.year\n",
    "        files = []\n",
    "        while _year <= self.edate.year:\n",
    "            \n",
    "            searchstr = fmtstr.format(_year)\n",
    "            fnames = glob(searchstr)\n",
    "            \n",
    "            if len(fnames) == 0:\n",
    "                _year = _year +1\n",
    "                continue\n",
    "            else:\n",
    "                files.append(fnames[0])\n",
    "           \n",
    "            _year = _year + 1\n",
    "\n",
    "        return files\n",
    "        \n",
    "        \n",
    "    def get_psd_at_frequency(self, freq):\n",
    "        \"\"\"\n",
    "        Get power spectral density at specific frequency\n",
    "        as time series (np.array).\n",
    "        \"\"\"\n",
    "        self.get_filenames()\n",
    "        file_iterator = self.iter_files()\n",
    "        f = next(file_iterator)\n",
    "        freqax = f[\"frequency_axis\"][:]\n",
    "        idx = np.where(np.isclose(freqax, freq, atol=freqax[1]/2))[0]\n",
    "        ista = get_proclen_index(f, self.starttime)\n",
    "        print(ista)\n",
    "        DATA = f[\"psds\"][ista:,:,idx].ravel().tolist()\n",
    "        \n",
    "        for f in file_iterator:\n",
    "            print(f)\n",
    "            data = f[\"psds\"][:,:,idx]\n",
    "            tsta = UTC(*f.attrs['starttime'])\n",
    "            ista = get_proclen_index(f, self.endtime)\n",
    "            DATA.extend(data.ravel().tolist())\n",
    "        print(data.shape)\n",
    "        nproc, nwin, _  = data.shape\n",
    "        size = data.size\n",
    "        ista = ista*nwin+nwin\n",
    "        print(ista, size)\n",
    "        DATA = DATA[:ista-size]\n",
    "        return np.array(DATA)\n",
    "    \n",
    "    \n",
    "def get_proclen_index(fin, t):\n",
    "    \n",
    "    tsta =  UTC(*fin.attrs['starttime'])\n",
    "    \n",
    "    if t < tsta:\n",
    "        raise ValueError(\"Given time %s is before start of file at %s\" %\n",
    "                        (tsta, t))\n",
    "    shape = fin[\"amplitudes\"].shape\n",
    "    \n",
    "    proclen_seconds = fin.attrs['seconds_per_proclen']\n",
    "    i = int((t - tsta) / proclen_seconds)\n",
    "    return i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60ff4815-7cd8-4346-87e1-320eebe74e78",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(base)\n",
    "# Station id\n",
    "network = 'GR'\n",
    "station = 'BFO'\n",
    "location = ''\n",
    "channel = 'HHZ'\n",
    "\n",
    "# Data source\n",
    "datadir = '/home/lehr/sds/processed/'\n",
    "#datadir = \".\"\n",
    "\n",
    "\n",
    "# Date range that you want to inspect\n",
    "startdate = UTC(\"2020-10-28\")\n",
    "enddate = UTC(\"2021-10-15\")\n",
    "\n",
    "\n",
    "# Choose time range \n",
    "## Full time range (= all 24h)\n",
    "stime, etime = \"00:00\", \"23:00\"\n",
    "\n",
    "\n",
    "stationcode = \"{}.{}.{}.{}\".format(network, station, \n",
    "                               location, channel)\n",
    "analyzer = SDSDataBaseAnalyzer(\n",
    "    startdate, enddate, datadir, stationcode, fileunit=\"year\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a004de57-2724-4862-8b45-f28b9a93f65c",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA = analyzer.get_psd_at_frequency(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a81065d3-1586-4c32-8080-7ab822f749c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(DATA)/24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd87cd36-db6f-44f0-aba8-ca4424abf1b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(DATA, '-')\n",
    "ymax = np.nanmean(DATA)# + 1*np.nanstd(DATA)\n",
    "plt.ylim(0, ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff22f2d8-cf10-4975-a347-6637405ef28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "analyzer.get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddc155ab-3b19-418b-84b6-b4560711a0ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log(analyzer.amps[:,:]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c0565e-db6c-4e74-94dd-57ab9cf670a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(np.log(analyzer.psds[:,:, 10]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d985276-fd12-41ab-ab2b-d0f3655bb89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "ymax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "012fabee-2101-48de-bb84-31d1eb64f440",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = analyzer.psds[:,:,100].ravel()\n",
    "ymax = np.nanpercentile(y, 99,)\n",
    "plt.plot(y, '-')\n",
    "plt.ylim(0,  ymax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65562112-dc2d-4fec-9c64-324705cee24a",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = 1.0\n",
    "file_iterator = analyzer.iter_files()\n",
    "f = next(file_iterator)\n",
    "freqax = f[\"frequency_axis\"][:]\n",
    "idx = np.where(np.isclose(freqax, freq, atol=freqax[1]/2))[0]\n",
    "print(idx)\n",
    "DATA = f[\"psds\"][:,:,idx].ravel().tolist()\n",
    "for f in file_iterator:\n",
    "    print(f)\n",
    "    data = f[\"psds\"][:,:,idx].ravel().tolist()\n",
    "    DATA.extend(data)\n",
    "DATA = np.array(DATA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d70846-78b9-4aca-b825-07d92d0a50f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4692ee8e-6f0d-4175-b050-2b660fd9dd42",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs = np.linspace(0.05, 19, 20) \n",
    "#freqs = np.linspace(0.05, 1, 20)\n",
    "freqs = np.linspace(0, 50, 26)\n",
    "print(freqs)\n",
    "for freq in freqs:\n",
    "    idx = np.where(np.isclose(freqax, freq, atol=freqax[1]/2))\n",
    "    print(idx, \"\\t\", freq, freqax[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bdb511f-33df-4797-bf3f-6868f890658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "freqs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c665f1b4-e7b7-417d-80dc-95ac5fd69fc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "it = analyzer.iter_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88cedef5-340a-4aaf-ba6f-00908610cd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = next(it)\n",
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b1b1e5-7ae3-4b67-8f7c-ab8cc095a9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "for f in it:\n",
    "    print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c3291f-4021-4c54-9537-dc2cc0ce061d",
   "metadata": {},
   "outputs": [],
   "source": [
    "f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02658fe-fbb1-4703-a0a4-0c4625ec8520",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92884f59-b664-4620-aff9-8bebd7ba5cb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.tile(np.arange(5), 10).reshape((5, 10)).T\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60bb743-c95a-4cef-a1f4-59abbe5e96d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2924793b-c222-4665-8c6f-1a0f9e2f53fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = np.arange(5).repeat(10)\n",
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "743ae1bb-4b60-4aaa-b198-7618f8a97880",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = pd.Series(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7d8670-9bc4-4a59-9df4-861ee0ff500c",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm = ds.rolling(window=20, center=True).median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "489dd7b3-e042-4172-91eb-2e599ae11199",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plt.plot(s, 'o')\n",
    "plt.plot(rm, 'x')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8513fc29-297c-45b6-a960-2866151c5bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "UTC(\"20-Dec-2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a29ba759-7978-497e-9707-1c4fdd77fd5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5102331f-acde-49b9-b518-90c408f88545",
   "metadata": {},
   "outputs": [],
   "source": [
    "datetime.datetime(\"20-Dec-2021\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e61f541c-0952-47e8-b05e-4d2449e6d3a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from importlib import reload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708c5a0e-e19f-4389-9f73-8f055b52c850",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_quality_control import util\n",
    "from obspy.core import UTCDateTime as UTC\n",
    "\n",
    "sdate = UTC(\"2018-05-14\")\n",
    "edate = UTC(\"2021-09-20\")\n",
    "for s, e in util.iter_years(sdate, edate):\n",
    "    print(\">>>>\", s.date, e.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a17bad0-374a-4666-9793-25399a68ebbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_quality_control import util\n",
    "from obspy.core import UTCDateTime as UTC\n",
    "\n",
    "sdate = UTC(\"2020-05-20\")\n",
    "edate = UTC(\"2021-10-25\")\n",
    "for s, e in util.iter_month(sdate, edate):\n",
    "    print(\">>>\", s.date, e.date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b218b52-c72e-4b6c-af0a-4397314ecd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "reload(util)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0de75d32-74d7-45e1-adbe-c1501bfe238e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_quality_control import util\n",
    "from obspy.core import UTCDateTime as UTC\n",
    "\n",
    "sdate = UTC(\"2020-05-20\")\n",
    "edate = UTC(\"2020-10-25\")\n",
    "for s, e in util.iter_timeinc(sdate, edate, \n",
    "                              12*3600, 4):\n",
    "    print(\">>>\", s, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed4a38d5-e1df-4bef-a59a-27bb9138c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954cafc7-ceac-4a53-9caf-7f31f7ed011c",
   "metadata": {},
   "outputs": [],
   "source": [
    "stime = UTC(\"2021-01-11\")\n",
    "quot, rem = np.divmod(stime.month + 1, 12)\n",
    "print(quot, rem)\n",
    "print(\"{:d}-{:02d}-01\".format(stime.year+quot, rem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04795506-adbf-4eca-bb07-587888e20ed3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
